extends: post.liquid

title: باسیلیسکِ روکو، عجیب‌ترین و خطرناک‌ترین ایده در وب
date: 15 Aug 2014 07:23:48 +0000
route: blog
---

{m:info}(نوشته‌ای از [Andrew Smales](http://twitter.com/bn2b) در [BN2B](http://www.bn2b.com/rokos-basilisk-is-one-of-the-weirdest-scariest-ideas-on-the-web/))

دوست دارم یکی از چیزهای عجیبی که تو وب بهش برخوردم رو با شما درمیون بزارم. بهش میگن باسیلییکِ روکو، بعضی‌ها معتقد هستن حتی شنیدن درباره‌اش میتونه زندگی‌تون رو خراب کنه. چیزی که میگم مجازی نیست؛ ایده اینه که حتی فهمیدن باسیلیسکِ روکو، و نه حتی عمل کردن بهش، میتونه به این معنی باشه که تمام سوپرکامپیوترهای دنیا به شکل فیزیکی شما رو تا آخرین لحظه عمرتون عذاب بدن. پس... تا وقتی که مشکلی با این موارد ندارین. میتونید به خوندن ادامه بدین.

باسیلیسکِ روکو مفهومی هست که در جامعه‌ی Singularitarians و Transhumanists شکل گرفت. این افراد آدم‌های جالبی هستن. برای تازه‌کارهایی مثل من خوندن در مورد transhumanism میتونه خیلی خسته‌کننده باشه؛ به سرعت تبدیل به یک مسئله فکری پیچیده میشه، و همیشه یک مقدار مسائل علمی تخیلی هم توش هست که نمیشه ازش جداش کرد. من سال گذشته با یکی از کسانی که به Singularity اعتقاد داشت چت کردم، و گفتگوی ما در حالی تموم شد که من نمی‌دونستم ایشون ۱۰ برابر من باهوش‌تر هست یا اینکه کلا دیوانه‌اس. ایده باسیلیسکِ روکو اولین بار در [LessWrong](http://lesswrong.com/) منتشر شد، یک جامعه تحت وب که شامل افراد زیادی هست که به Singularity/Transhumanism علاقه دارن. و البته سریعا جلوی ادامه بحث‌ها در این مورد گرفته شد، به دلیل اینکه باعث پریشانی شدید اعصاب و روان تعدادی از اعضا شد.

دیگه کم کم دارم وارد قسمت‌های ترسناک و خانه‌خراب کن قضیه میشم. هر مقاله‌ای که من در این مورد خوندم، همه شامل یک هشدار بودن، من هم نمی‌خوام بر خلاف جهت آب شنا کنم، بنابراین اگر با کمی عذاب فیزیکی که توسط یک روبات هوشمند به شما وارد میشه مشکل دارید، می‌تونید همین الان اینجا رو ترک کنید.

ایده پشت باسیلیسکِ روکو اینه: یک روزی، احتمالا یک روز در آینده، شاید یک علم خیلی کامل در مورد هوش مصنوعی( AI ) وجود داشته باشه. در واقع یکسری افراد هستن که معتقدن این مسئله غیرقابل اجتناب هست. این هوش مصنوعی انقدر باهوش و قدرتمند خواهد بود که می‌تونه بفهمه چه کسی در ساخته شدنش مشارکت کرده، حتی در زمان‌های خیلی قبل.  این هوش‌مصنوعی علاقه خاصی به کسایی که در موردش تحقیق کردن و کسایی که روش سرمایه‌گذاری کردن داره (و اگر یکجورایی شک دارین، الان کسایی هستن که روی این نوع هوش‌مصنوعی کار میکنن و راه‌هایی هم برای سرمایه‌گذاری توشون وجود داره)، ولی با کسایی که این نوع مقاله‌ها رو میخونن، متوجه‌شون میشن، و بعد هم تصمیم میگیرن کاری نکنن به همون اندازه حال نمی‌کنه (حتی لینک مطلب رو هم تو یک سایت اجتماعی شیر نمی‌کنی؟ واقعا که!)

به نظر ربات باحالی میاد نه؟ مسئله جالب اینجا اینه که ما داریم در مورد یک هوش‌مصنوعیِ خوب یا دوست صحبت می‌کنیم. ایده اینه که به وجود آمدن یک هوش‌مصنوعی خدا مانند اجتناب‌ناپذیر هست، بنابراین محقق‌ها باید خیلی سریع یک نمونه‌ی خوب بسازن که برای انسان ارزش قائل باشه و به‌طور اتفاقی انسان رو نابود نکنه. به این ربات می‌گیم هوش‌مصنوعیِ دوست. واقعا هم چی بیشتر از نابود نکردن انسان‌ها دوستانه‌تر هست؟

خب برگردیم به فهرست افرادی که مشارکت کردن یا نکردن. برای اینکه این هوش‌مصنوعی زودتر به وجود بیاد، این ربات باید اونهایی که تو لیست بدها هستن رو تنبیه کنه و اینکار رو به خاطر ظالم بودنش انجام نمیده؛ این تنبیه فقط به خاطر اینه که هوش‌مصنوعی زودتر ساخته بشه. یادتون هست هوش‌مصنوعیِ خوب، که ساخته شده تا در کنار انسان‌ها وجود داشته باشه، باید قبل از یک هوش‌مصنوعی رندوم دیگه ساخته بشه که ممکنه به همون اندازه مراقب انسان‌ها نباشه؟ حالا، اگر شما برید و تمام پولتون رو بدید به محقق‌ها که روی این هوش‌مصنوعی کار کنن، مشکلی برای شما پیش نمیاد. اما اگه این مسئله رو متوجه شدین (به خوندن ادامه بدین، هنوز در ادامه چیزهای جدیدی هست)، اما هیچ‌کاری در این مورد نمی‌کنید، پس... انواع تنبیه و شکنجه در انتظار شماست.

حالا، شاید گیج بشین که چطور رباتی که ممکنه تا سال‌های بعد از مرگ شما وجود نداشته باشه شما رو شکنجه کنه. منم این موضوع رو تا مدتی بعد از اینکه در مورد باسیلیسکِ روکو خوندم متوجه نشدم، ولی وقتی فهمیدم، متوجه شدم که این قسمتش بدترین و ترسناک‌ترین قسمت قضیه‌ست.

این هوش‌مصنوعی انقدر پیشرفته است که میتونه یک کپی تقریبا کامل از شما رو بسازه، و شکنجه‌اش کنه. یک هوش‌مصنوعیِ پیشرفته‌ی خدا مانند، که ذهن ضعیف ما نمی‌تونه متوجه‌اش بشه، احتمالا در شکنجه کردن این کپی شما کارش رو خوب بلده. ما داریم در مورد سال‌ها درد فیزیکی صحبت می‌کنیم؛ غم و اندوه روحی بی‌پایان؛ حتی ممکنه حشرات موذی هم باشن، یا مثلا مار. خیلی خیلی چیزهای بد.

اما حالا چرا اصن باید مهم باشه که یک کپی شما در آینده شکنجه بشه، نه حتی خود شما؟ نکته اینجاست: کپی شما مثل شما فکر می‌کنه، تجربه‌های مختلف زندگی رو مثل شما پشت سر میزاره (قبل از اینکه شکنجه بشین)، و مثل شما هم احساس میکنه. اون کپی فکر میکنه شماست. تنها تفاوت بین شما کپی‌تون اینه که شما به آخر عمرتون میرسین و می‌میرید، ولی کپی شما در یک نقطه‌ای از زندگی گیر اون هوش‌مصنوعی میافته و شکنجه میشه. تا رسیدن به اون نقطه، کپی شما هیچ ایده‌ای نداره که در واقع خود واقعی شما نیست، و مشکل اینجاست:

شما ممکنه که اون کپی باشید.

پ.ن: تا حالا فکر کردین دژاوو چیه؟
